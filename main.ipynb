{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('X_test_GgyECq8.csv')\n",
    "X_train = pd.read_csv('X_train_Wwou3IE.csv')\n",
    "y_train = pd.read_csv('y_train_jJtXgMX.csv')\n",
    "y_pred = pd.read_csv('y_random_pt8afo8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DELIVERY_START', 'load_forecast', 'coal_power_available',\n",
       "       'gas_power_available', 'nucelear_power_available',\n",
       "       'wind_power_forecasts_average', 'solar_power_forecasts_average',\n",
       "       'wind_power_forecasts_std', 'solar_power_forecasts_std',\n",
       "       'predicted_spot_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DELIVERY_START', 'spot_id_delta'], dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_accuracy(y_actual, y_pred):\n",
    "    # If y_actual is a DataFrame, extract the 'spot_id_delta' column, otherwise assume it's already a numpy array\n",
    "    if isinstance(y_actual, pd.DataFrame):\n",
    "        actual = y_actual[\"spot_id_delta\"].values\n",
    "    else:\n",
    "        actual = y_actual\n",
    "    \n",
    "    # If y_pred is a DataFrame, extract the 'spot_id_delta' column, otherwise assume it's already a numpy array\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        predicted = y_pred[\"spot_id_delta\"].values\n",
    "    else:\n",
    "        predicted = y_pred\n",
    "    \n",
    "    # actual = y_actual[\"spot_id_delta\"].values\n",
    "    # predicted = y_pred[\"spot_id_delta\"].values\n",
    "\n",
    "    correct_direction = (np.sign(actual) == np.sign(predicted)).astype(int)\n",
    "\n",
    "    weights = np.abs(actual)\n",
    "\n",
    "    weighted_accuracy = np.sum(correct_direction * weights) / np.sum(weights)\n",
    "\n",
    "    return round(weighted_accuracy, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Best Model: RandomForestRegressor(max_depth=5, n_estimators=200, random_state=42)\n",
      "Train Metrics - MSE: 1236.642890502967 MAE: 19.883611270098992 Weighted Accuracy: 0.74\n",
      "Validation Metrics - MSE: 1598.1035587384122 MAE: 26.34907172839559 Weighted Accuracy: 0.79\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Test Metrics - MSE: 1388.2375254835695 MAE: 20.51665193117456 Weighted Accuracy: 0.42\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(df):\n",
    "    # Ensure 'DELIVERY_START' is set as the index with timezone handling\n",
    "    if 'DELIVERY_START' in df.columns:\n",
    "        df['DELIVERY_START'] = pd.to_datetime(df['DELIVERY_START'], utc=True)  # Parse with timezone info\n",
    "        df = df.set_index('DELIVERY_START')\n",
    "        df.index = df.index.tz_convert('Europe/Berlin')  # Adjust to desired timezone, if needed\n",
    "\n",
    "    # Add time-related features\n",
    "    df['hour'] = df.index.hour\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['month'] = df.index.month\n",
    "\n",
    "    # Handle missing values, encode categoricals, etc.\n",
    "    df = df.fillna(0)  # Fill missing values with 0 (adjust as needed)\n",
    "    df = pd.get_dummies(df, drop_first=True)  # Encode categorical variables\n",
    "\n",
    "    # Drop unwanted columns\n",
    "    df = df.drop(columns=['wind_power_forecasts_std', 'solar_power_forecasts_std'], errors='ignore')\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess_y(y):\n",
    "    # Ensure 'DELIVERY_START' is set as the index\n",
    "    if 'DELIVERY_START' in y.columns:\n",
    "        y['DELIVERY_START'] = pd.to_datetime(y['DELIVERY_START'], utc=True)  # Parse with timezone info\n",
    "        y = y.set_index('DELIVERY_START')\n",
    "        y.index = y.index.tz_convert('Europe/Berlin')  # Adjust to desired timezone\n",
    "    return y\n",
    "\n",
    "def split_train_data(X, y):\n",
    "    # Ensure indices align during split\n",
    "    split_size = len(X) // 3\n",
    "    X_train1, X_train2, X_train3 = X.iloc[:split_size], X.iloc[split_size:2*split_size], X.iloc[2*split_size:]\n",
    "    y_train1, y_train2, y_train3 = y.iloc[:split_size], y.iloc[split_size:2*split_size], y.iloc[2*split_size:]\n",
    "    return X_train1, X_train2, X_train3, y_train1, y_train2, y_train3\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train.values.ravel())  # Ensure y is passed as a 1D array\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X, y_actual):\n",
    "    # Predict on the given dataset\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    # Compute regression metrics\n",
    "    mse = mean_squared_error(y_actual, predictions)\n",
    "    mae = mean_absolute_error(y_actual, predictions)\n",
    "    \n",
    "    # Use custom weighted accuracy\n",
    "    y_pred_df = pd.DataFrame(predictions, index=X.index, columns=[\"spot_id_delta\"])\n",
    "    weighted_acc = compute_weighted_accuracy(y_actual, y_pred_df)\n",
    "    \n",
    "    return mse, mae, weighted_acc\n",
    "\n",
    "def tune_hyperparameters(X_train2, y_train2):\n",
    "    # Flatten y_train2 to 1D array\n",
    "    y_train2 = y_train2.values.ravel()  # Ensure y is 1D array\n",
    "    # Define the model\n",
    "    rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "    # Set up the hyperparameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [5, 10, 20],\n",
    "    }\n",
    "\n",
    "    # Perform GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "    \n",
    "    grid_search.fit(X_train2, y_train2)\n",
    "\n",
    "    # Return the best model and parameters\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "def launch(X_train, y_train, X_test):\n",
    "    # Preprocess X_train and X_test\n",
    "    X_train = preprocess_data(X_train)\n",
    "    X_test = preprocess_data(X_test)\n",
    "\n",
    "    # Preprocess y_train (only index adjustment)\n",
    "    y_train = preprocess_y(y_train)\n",
    "\n",
    "    # Split data into 3 parts\n",
    "    X_train1, X_train2, X_train3, y_train1, y_train2, y_train3 = split_train_data(X_train, y_train)\n",
    "\n",
    "    # Tune hyperparameters using the validation set (X_train2 and y_train2)\n",
    "    best_model, best_params = tune_hyperparameters(X_train2, y_train2)\n",
    "\n",
    "    # Train the model on the full training set (X_train1 + X_train2)\n",
    "    X_train_full = pd.concat([X_train1, X_train2])\n",
    "    y_train_full = pd.concat([y_train1, y_train2])\n",
    "\n",
    "    # Flatten y_train_full to 1D array\n",
    "    y_train_full = y_train_full.values.ravel()  # Ensure y is 1D array\n",
    "\n",
    "    # Train the model on the full training data\n",
    "    best_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "    # Evaluate the model on the full training data (X_train_full)\n",
    "    train_mse, train_mae, train_weighted_acc = evaluate_model(best_model, X_train_full, y_train_full)\n",
    "\n",
    "    # Validate on the validation set (X_train2, y_train2)\n",
    "    val_mse, val_mae, val_weighted_acc = evaluate_model(best_model, X_train2, y_train2)\n",
    "\n",
    "    # Test on the test set (X_train3, y_train3)\n",
    "    test_mse, test_mae, test_weighted_acc = evaluate_model(best_model, X_train3, y_train3)\n",
    "\n",
    "    # Apply model to the actual test dataset\n",
    "    predictions_test = best_model.predict(X_test)\n",
    "    y_pred_test = pd.DataFrame(predictions_test, index=X_test.index, columns=[\"spot_id_delta\"])\n",
    "\n",
    "    return best_model, (train_mse, train_mae, train_weighted_acc), (val_mse, val_mae, val_weighted_acc), (test_mse, test_mae, test_weighted_acc), y_pred_test\n",
    "\n",
    "# Execute the pipeline\n",
    "model, train_metrics, val_metrics, test_metrics, y_pred_test = launch(X_train, y_train, X_test)\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"Best Model:\", model)\n",
    "print(\"Train Metrics - MSE:\", train_metrics[0], \"MAE:\", train_metrics[1], \"Weighted Accuracy:\", train_metrics[2])\n",
    "print(\"Validation Metrics - MSE:\", val_metrics[0], \"MAE:\", val_metrics[1], \"Weighted Accuracy:\", val_metrics[2])\n",
    "print('------------------------------------------------------------------------------------------------------')\n",
    "print(\"Test Metrics - MSE:\", test_metrics[0], \"MAE:\", test_metrics[1], \"Weighted Accuracy:\", test_metrics[2])\n",
    "\n",
    "# Save predictions\n",
    "y_pred_test.to_csv('y_pred_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
